{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementación de una DCGAN en PyTorch usando el conjunto de datos CelebA**\n",
        "Seguiremos el tutorial de la documentación de PyTorch, que puede encontrarse en [Tutorial DCGAN](https://docs.pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html), donde se implementa una DCGAN siguiendo la arquitectura y recomendaciones del artículo original de las DCGAN  ([Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434))."
      ],
      "metadata": {
        "id": "itV4DK9kt2-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerías necesarias:\n",
        "Primero, empezamos importando las librerías requeridas:"
      ],
      "metadata": {
        "id": "C9s6BaPLtHmS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dSvyP9R0paN"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Fijamos la semilla de los números aleatorios para poder reproducirlo:\n",
        "\n",
        "#semilla_manual = 999\n",
        "semilla_manual = random.randint(1, 10000) # para nuevos resultados\n",
        "print(\"Semilla aleatoria: \", semilla_manual)\n",
        "random.seed(semilla_manual)\n",
        "torch.manual_seed(semilla_manual)\n",
        "torch.use_deterministic_algorithms(True) # Necesario para resultados reproducibles"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir los parámetros de entrada de la DCGAN:\n",
        "Ahora, definimos los hiperparámetros del modelo DCGAN, como la tasa de aprendizaje, el número de épocas, el tamaño del minilote o la dimensión de las imágenes generadas y del espacio latente:"
      ],
      "metadata": {
        "id": "1xnFyo_kuV5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128    # Tamaño del minilote (batch) durante el entrenamiento\n",
        "image_size = 64     # Dimensión espacial de las imágenes de entrenamiento. Todas las imágenes se redimensionarán a este tamaño mediante una transformación\n",
        "image_channels = 3  # Número de canales de las imágenes de entrenamiento. Para imágenes a color (RGB) es 3\n",
        "latent_dim = 100    # Dimensión de un vector z del espacio latente (es decir, de la entrada del generador)\n",
        "ngf = 64            # Tamaño del mapa de características del generador\n",
        "ndf = 64            # Tamaño del mapa de características del discriminador\n",
        "num_epochs = 20     # Número de épocas de entrenamiento\n",
        "lr = 0.0002         # Tasa de aprendizaje (learning rate) para la optimización\n",
        "beta1 = 0.5         # Hiperparámetro Beta1 del optimizador Adam\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Decidir en qué unidad queremos ejecutarlo"
      ],
      "metadata": {
        "id": "AUtqcptjv6Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar el conjunto de datos CelebA:\n",
        "Hay varias formas de cargar conjuntos de datos en Google Colab. Asumiremos que hemos descargado el conjunto de datos de [CelebA Dataset](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) y que hemos guardado el archivo img_align_celeb.zip en la carpeta \"/datasets/celeba\" de Google Drive. Después, montaremos Google Drive en Google Colab para poder acceder a los archivos en Drive y extraer el contenido del archivo zip en una carpeta \"/content/celeba\". Después, confirmaremos que tenemos el contenido deseado:\n"
      ],
      "metadata": {
        "id": "Kp5cBkwHwE4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CelebA dataset:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip -n /content/drive/MyDrive/datasets/celeba/img_align_celeba.zip -d /content/celeba\n",
        "!ls /content/celeba\n",
        "!ls /content/celeba/img_align_celeba | head"
      ],
      "metadata": {
        "id": "DT-6TDotkeoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, podemos crear el dataset en PyTorch, prepararlo para el entrenamiento y visualizar algunas de las imágenes de entrenamiento:"
      ],
      "metadata": {
        "id": "42eJGAEkx3xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataroot = \"/content/celeba\" # Dirección de la carpeta del dataset\n",
        "workers = 2 # Número de trabajadores para dataloader\n",
        "\n",
        "# Crear el dataset:\n",
        "dataset = datasets.ImageFolder(root=dataroot,\n",
        "                               transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "# Cargar los datos en minilotes con el dataloader:\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "# Visualizar imágenes de entrenamiento:\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Imágenes de entrenamiento\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a9NQOGK7l-UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inicializar pesos:\n",
        "Inicializaremos los pesos que usaremos para entrenar al discriminador y al generador siguiendo una distribución N(0,0.02):"
      ],
      "metadata": {
        "id": "H-G27g3Z7a6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "J0OR9BUA8uju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir la arquitectura del modelo DCGAN\n",
        "## Crear la red del Generador:\n",
        "El generador está diseñado para transformar un vector del espacio latente de dimensiones 100x1x1 en una imagen de dimensiones 3x64x64.\n",
        "\n",
        "La red Generador estará implementada como una serie de capas convolucionales traspuestas, aplicando normalización del minilote tras cada una y usando ReLU como función de activación en todas excepto para la capa de salida, que usa tanh."
      ],
      "metadata": {
        "id": "V916TLvf8vF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            # Entrada: vector z. Dimensión: 100 x 1 x 1\n",
        "            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # Dimensión: (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # Dimensión: (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # Dimensión: (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # Dimensión: (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, image_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "\n",
        "            # Dimensión de la salida: (image_channels) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# Crear el generador:\n",
        "netG = Generator().to(device)\n",
        "\n",
        "# Aplicar la función weights_init para inicializar los pesos:\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# Imprimir la red G:\n",
        "print(netG)\n"
      ],
      "metadata": {
        "id": "T4s692w0ojC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear la red del Discriminador:\n",
        "El discriminador es un clasificador binario que toma como entrada una imagen de dimensiones 3x64x64 y devuelve un valor que representa la probabilidad de que la imagen de entrada sea real, es decir, una salida de dimensión 1x1x1.\n",
        "\n",
        "La red Discriminador estará implementada como una serie de capas convolucionales, usando normalización del minilote tras cada una y LeakyReLU como función de activación en todas excepto para la salida, que usa sigmoide."
      ],
      "metadata": {
        "id": "P-8JQqgkCg2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            # Dimensión de la entrada: (image_channels) x 64 x 64\n",
        "            nn.Conv2d(image_channels, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Dimensión: (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Dimensión: (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Dimensión: (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Dimensión: (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# Crear el discriminador:\n",
        "netD = Discriminator().to(device)\n",
        "\n",
        "# Aplicar la función weights_init para inicializar los pesos:\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# Imprimir la red D:\n",
        "print(netD)"
      ],
      "metadata": {
        "id": "g0qlnJPiukBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir la función de pérdida y los optimizadores:\n",
        "Usaremos la función de pérdida de la entropía cruzada binaria (BCE, Binarry Cross-Entropy) y el optimizador Adam."
      ],
      "metadata": {
        "id": "-SZLx8UAEJVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar la función de pérdida entropía cruzada binaria (BCE):\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Crear un minilote de 64 vectores latentes que usaremos para\n",
        "# visualizar la evolución del generador:\n",
        "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n",
        "\n",
        "# Visualizamos el espacio latente inicial:\n",
        "with torch.no_grad():\n",
        "    fake_init = netG(fixed_noise).detach().cpu()\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Espacio latente antes del entrenamiento\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake_init, padding=2, normalize=True), (1,2,0)))\n",
        "plt.show()\n",
        "\n",
        "# Establecemos las etiquetas para las muestras reales y falsas durante el\n",
        "# entrenamiento:\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Optimizadores Adam para D y G:\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "MuVDiPI0viJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento del modelo DCGAN:\n",
        "Entrenaremos el modelo aplicando el algoritmo de descenso de gradiente estocástico (SGD) por minilotes, entrenando primero D y después G en cada iteración.\n",
        "\n",
        "Para seguir la evolución, guardaremos las pérdidas de D y G y se imprimirán cada 50 iteraciones. Además, visualizaremos y guardaremos imágenes generadas por G tras cada época.\n",
        "We will train the model applying mini-batch stochastic gradient descent (SGD)."
      ],
      "metadata": {
        "id": "ZtDQBf22Ey-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listas para seguir el proceso:\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "img_list = []\n",
        "\n",
        "print(\"Comenzando bucle de entrenamiento...\")\n",
        "# Por cada época:\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Por cada minilote en el dataloader:\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ### (1) Actualizar la red D: maximizar log(D(x)) + log(1 - D(G(z)))\n",
        "\n",
        "        netD.zero_grad()\n",
        "\n",
        "        ## Entrenar con minilote de muestras reales:\n",
        "\n",
        "        # Formato del minilote:\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "\n",
        "        # Propagar el minilote real a través de D:\n",
        "        output_real = netD(real_cpu).view(-1)\n",
        "\n",
        "        # Calcular el error para las muestras reales:\n",
        "        errD_real = criterion(output_real, label)\n",
        "\n",
        "        # Calcular los gradientes de D para la retropropagación:\n",
        "        errD_real.backward()\n",
        "        D_x = output_real.mean().item()\n",
        "\n",
        "        ## Entrenar con minilote de muestras falsas:\n",
        "\n",
        "        # Generar minilote de vectores latentes:\n",
        "        noise = torch.randn(b_size, latent_dim, 1, 1, device=device)\n",
        "\n",
        "        # Generar minilote de muestras falsas con G:\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "\n",
        "        # Clasificar las muestras falsas con D:\n",
        "        output_fake = netD(fake.detach()).view(-1)\n",
        "\n",
        "        # Calcular el error de D para las muestras falsas:\n",
        "        errD_fake = criterion(output_fake, label)\n",
        "\n",
        "        # Caclular los gradientes de D del minilote de muestras falsas:\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output_fake.mean().item()\n",
        "\n",
        "        # Sumar el error de D sobre las muestras reales y las falsas:\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        # Actualizar D:\n",
        "        optimizerD.step()\n",
        "\n",
        "        ### (2) Actualizar la red G: maximizar log(D(G(z)))\n",
        "\n",
        "        netG.zero_grad()\n",
        "\n",
        "        label.fill_(real_label)  # las etiquetas de las muestras falsas se ponen como reales para calcular el coste de G\n",
        "\n",
        "        # Como acabamos de actualizar D, propagamos de nuevo el minilote de muestras falsas a través de D:\n",
        "        output = netD(fake).view(-1)\n",
        "\n",
        "        # Calcular el error de G para sus muestras (falsas):\n",
        "        errG = criterion(output, label)\n",
        "\n",
        "        # Calcular los gradientes de G:\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "\n",
        "        # Actualizar G:\n",
        "        optimizerG.step()\n",
        "\n",
        "        ### Evolución del entrenamiento:\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tPérdida_D: %.4f\\tPérdida_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        ### Guardamos las pérdidas para graficarlas después:\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "    ### Visualizamos y guardamos los resultados tras cada época:\n",
        "    with torch.no_grad():\n",
        "      fake = netG(fixed_noise).detach().cpu()\n",
        "\n",
        "    grid = vutils.make_grid(fake, padding=2, normalize=True)\n",
        "    img_list.append(grid)\n",
        "\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Época {epoch}\")\n",
        "    plt.imshow(np.transpose(vutils.make_grid(fake, padding=2, normalize=True), (1,2,0)))\n",
        "    plt.show()\n",
        "\n",
        "    os.makedirs(\"/content/drive/MyDrive/dcgan_progress\", exist_ok=True)\n",
        "    vutils.save_image(fake, f\"/content/drive/MyDrive/dcgan_progress/epoch_{epoch:03d}.png\", normalize=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "IOZ4ON4IwkRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar el modelo entrenado:"
      ],
      "metadata": {
        "id": "pEJg5sBGGSxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/models\", exist_ok=True)\n",
        "\n",
        "torch.save(netG.state_dict(), \"/content/drive/MyDrive/models/G.pth\")\n",
        "torch.save(netD.state_dict(), \"/content/drive/MyDrive/models/D.pth\")\n",
        "\n",
        "torch.save(optimizerG.state_dict(), \"/content/drive/MyDrive/models/optimizerG.pth\")\n",
        "torch.save(optimizerD.state_dict(), \"/content/drive/MyDrive/models/optimizerD.pth\")"
      ],
      "metadata": {
        "id": "qpi4mG_tsNqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados:\n",
        "## 1. Gif animado de la evolución del entrenamiento del modelo DCGAN"
      ],
      "metadata": {
        "id": "s3JXIK4mEoVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "\n",
        "font = ImageFont.load_default()\n",
        "\n",
        "for i, img in enumerate(img_list):\n",
        "\n",
        "    frame = np.transpose(img.numpy(), (1,2,0))\n",
        "    frame = (frame * 255).astype(np.uint8)\n",
        "\n",
        "    pil_img = Image.fromarray(frame)\n",
        "\n",
        "    text_height_space = 30\n",
        "    canvas = Image.new('RGB', (pil_img.width, pil_img.height + text_height_space), color='white')\n",
        "    canvas.paste(pil_img, (0,0))\n",
        "\n",
        "    draw = ImageDraw.Draw(canvas)\n",
        "    text = f\"Época {i}\"\n",
        "\n",
        "    bbox = draw.textbbox((0,0), text, font=font)\n",
        "    text_width = bbox[2] - bbox[0]\n",
        "    text_height = bbox[3] - bbox[1]\n",
        "\n",
        "    x = (canvas.width - text_width) // 2\n",
        "    y = pil_img.height + (text_height_space - text_height) // 2\n",
        "    draw.text((x, y), text, fill='black', font=font)\n",
        "\n",
        "    frames.append(np.array(canvas))\n",
        "\n",
        "# Guardar y visualizar gif:\n",
        "os.makedirs(\"/content/drive/MyDrive/dcgan_progress\", exist_ok=True)\n",
        "gif_file = os.path.join(\"/content/drive/MyDrive/dcgan_progress\", \"dcgan_training.gif\")\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "metadata": {
        "id": "I5cx1JdLExxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Comparación de imágenes reales vs imágenes falsas"
      ],
      "metadata": {
        "id": "IfWDcNjqGhpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomar un minilote de imágenes reales\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Visualizar las imágenes reales:\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Imágenes reales\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Visualizar las imágenes falsas:\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Imágenes falsas\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake, padding=5, normalize=True), (1,2,0)))\n",
        "plt.savefig(\"/content/drive/MyDrive/dcgan_progress/comparison.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uFhVJFFy4YSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Gráfica de la pérdida del generador y el discriminador durante el entrenamiento"
      ],
      "metadata": {
        "id": "uqWaTAvyGu3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Pérdida del generador y el discriminador durante el entrenamiento\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iteraciones\")\n",
        "plt.ylabel(\"pérdida\")\n",
        "plt.legend()\n",
        "plt.savefig(\"/content/drive/MyDrive/dcgan_progress/losses.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BDYaY9sD48kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Generar imágenes artificiales a partir de nuevos vectores de ruido aleatorio"
      ],
      "metadata": {
        "id": "NNH-D0PRG-Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "latent_dim = 100\n",
        "new_images = 4\n",
        "fixed_noise = []\n",
        "for j in range(new_images):\n",
        "  fixed_noise.append(torch.randn(64, latent_dim, 1, 1, device=device)) # generamos new_images conjuntos de 64 vectores aleatorios\n",
        "\n",
        "  # Generar nuevas imágenes dando a G como entrada los vectores de ruido:\n",
        "  with torch.no_grad():\n",
        "    fake = netG(fixed_noise[j]).detach().cpu()\n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Imagen generada \" f\"{j+1}\")\n",
        "  plt.imshow(np.transpose(vutils.make_grid(fake, padding=2, normalize=True), (1,2,0)))\n",
        "  plt.show()\n",
        "\n",
        "  os.makedirs(\"/content/drive/MyDrive/dcgan_progress\", exist_ok=True)\n",
        "  vutils.save_image(fake, f\"/content/drive/MyDrive/dcgan_progress/generated_{j+1}.png\", normalize=True)\n"
      ],
      "metadata": {
        "id": "-t7RLrIaYnG-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}